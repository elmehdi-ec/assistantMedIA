import streamlit as st
import pandas as pd
import os
import configparser
import requests

# ---------- Configuration ----------
st.set_page_config(page_title="Assistant IA clinique", layout="wide")
config = configparser.ConfigParser()
config.read('config.ini')
HF_TOKEN = config.get("default", "HF_TOKEN", fallback=None)

# ---------- Fonctions ----------
def load_data():
    data = pd.DataFrame([
        {"Nom": "Ahmed", "√Çge": 65, "Sexe": "Homme", "Sympt√¥mes": "Fi√®vre, toux, essoufflement", "Gravit√©": 8},
        {"Nom": "Salma", "√Çge": 32, "Sexe": "Femme", "Sympt√¥mes": "C√©phal√©e, douleur oreille", "Gravit√©": 3},
        {"Nom": "Youssef", "√Çge": 74, "Sexe": "Homme", "Sympt√¥mes": "Confusion, chute r√©cente", "Gravit√©": 9},
        {"Nom": "Imane", "√Çge": 19, "Sexe": "Femme", "Sympt√¥mes": "Maux gorge, fi√®vre", "Gravit√©": 4},
    ])
    return data

def generer_resume(symptomes):
    prompt = f"Voici un r√©sum√© m√©dical des sympt√¥mes suivants : {symptomes}"
    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "inputs": prompt,
        "parameters": {"max_new_tokens": 100}
    }
    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/google/flan-t5-large",
            headers=headers,
            json=payload,
            timeout=20
        )
        if response.status_code == 200:
            return response.json()[0]["generated_text"]
        else:
            return f"‚ùå Erreur API: {response.status_code}"
    except Exception as e:
        return f"‚ö†Ô∏è Erreur : {e}"

# ---------- UI ----------
st.title("üìã Cas cliniques")
df = load_data()
mode_demo = st.sidebar.checkbox("üéõÔ∏è Activer le mode d√©mo (offline)", value=False)

profil_medecin = st.sidebar.selectbox("üßë‚Äç‚öïÔ∏è Profil :", options=df["Nom"].unique())
st.markdown(f"### Bienvenue **{profil_medecin}** ü©∫")

if HF_TOKEN:
    st.success(f"üîê Token Hugging Face d√©tect√©. D√©but: `{HF_TOKEN[:8]}...`")
else:
    st.warning("‚ö†Ô∏è Aucun HF_TOKEN d√©tect√© dans le fichier `config.ini`.")

# ---------- Table ----------
df_display = df.copy()
df_display["R√©sum√© IA"] = ""

if st.button("üß† G√©n√©rer les r√©sum√©s IA"):
    if mode_demo or not HF_TOKEN:
        df_display["R√©sum√© IA"] = df["Sympt√¥mes"].apply(lambda x: "Mode d√©mo ‚Äî r√©sum√© non g√©n√©r√©")
    else:
        with st.spinner("‚è≥ Envoi des cas au moteur IA..."):
            df_display["R√©sum√© IA"] = df["Sympt√¥mes"].apply(generer_resume)
        st.success("‚úÖ R√©sum√©s IA g√©n√©r√©s.")

# ---------- Output ----------
st.dataframe(df_display)

# ---------- Export ----------
csv = df_display.to_csv(index=False).encode('utf-8')
st.download_button("üì• T√©l√©charger les cas enrichis (.csv)", csv, "cas_cliniques.csv", "text/csv")

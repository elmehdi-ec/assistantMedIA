import requests
import yaml
import os

# ğŸ“ Charger le profil mÃ©decin
def charger_profil(medecin_id):
    try:
        with open("config/medecins.yaml", "r", encoding="utf-8") as file:
            profils = yaml.safe_load(file)
        return profils.get(medecin_id, {})
    except Exception:
        return {}

# ğŸ§  GÃ©nÃ©rer le rÃ©sumÃ© IA
def generer_resume(symptomes, medecin_id, HF_TOKEN, mode_demo=False):
    profil = charger_profil(medecin_id)
    langue = profil.get("langue", "fr")
    specialite = profil.get("specialite", "mÃ©decine gÃ©nÃ©rale")

    # ğŸ’¬ Prompt adaptÃ©
    prompt = (
        f"Tu es un mÃ©decin spÃ©cialiste en {specialite}. RÃ©sume les symptÃ´mes suivants en style clinique, en {langue} : {symptomes}"
    )

    # ğŸ” Mode dÃ©mo = rÃ©ponse simulÃ©e
    if mode_demo:
        return f"[RÃ©sumÃ© IA simulÃ© en {langue}] : Patient prÃ©sente {symptomes.lower()}."

    # ğŸ”Œ Appel API Hugging Face
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    payload = {"inputs": prompt}

    try:
        url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2"
        response = requests.post(url, headers=headers, json=payload, timeout=20)
        if response.status_code == 200:
            output = response.json()
            return output[0]["generated_text"]
        else:
            return f"[Fallback IA] SymptÃ´mes dÃ©tectÃ©s : {symptomes}. RÃ©sumÃ© manuel en cours."
    except Exception:
        return f"[âš ï¸ IA indisponible] RÃ©sumÃ© simulÃ© : {symptomes.lower()}"

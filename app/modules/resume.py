import os
import requests

def generer_resume(symptomes, medecin_id, hf_token, mode_demo=False):
    if mode_demo or not hf_token:
        return "ğŸ§ª RÃ©sumÃ© simulÃ© : le patient prÃ©sente des signes compatibles avec une pathologie respiratoire."

    url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2"
    prompt = f"En tant que mÃ©decin {medecin_id}, rÃ©sume cliniquement ce cas : {symptomes}"
    headers = {"Authorization": f"Bearer {hf_token}"}
    payload = {"inputs": prompt}

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        result = response.json()

        # âœ… Correction : Hugging Face retourne une LISTE avec un champ "generated_text"
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        else:
            return "âš ï¸ RÃ©sumÃ© vide ou inattendu â€” modÃ¨le IA nâ€™a pas rÃ©pondu comme prÃ©vu."
    except Exception as e:
        return f"âŒ Erreur lors de lâ€™appel IA : {str(e)}"

import requests

def generer_resume(symptomes: str, medecin_id: str, hf_token: str, mode_demo: bool = False) -> str:
    if mode_demo or hf_token is None:
        return f"(Mode d√©mo actif) R√©sum√© simul√© : {symptomes[:40]}..."

    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }

    # üß† Prompt m√©dical structur√© pour Bloomz
    prompt = f"""
Vous √™tes m√©decin urgentiste.
Voici un cas clinique :
Patient : {medecin_id}
Sympt√¥mes : {symptomes}

R√©digez un r√©sum√© m√©dical synth√©tique en fran√ßais incluant :
- Hypoth√®se diagnostique
- Conduite √† tenir
- Examens compl√©mentaires recommand√©s
"""

    payload = { "inputs": prompt.strip() }

    try:
        # ‚úÖ Mod√®le stable et accessible via Hugging Face Inference API
        url = "https://api-inference.huggingface.co/models/bigscience/bloomz"
        response = requests.post(url, headers=headers, json=payload, timeout=60)

        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            else:
                return f"‚ö†Ô∏è Format inattendu : {data}"
        else:
            return f"‚ùå Erreur {response.status_code} : {response.text[:100]}"
    except Exception as e:
        return f"‚ùå Erreur lors de l‚Äôappel IA : {str(e)}"

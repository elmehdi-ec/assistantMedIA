import requests

def generer_resume(symptomes: str, medecin_id: str, hf_token: str, mode_demo: bool = False) -> str:
    if mode_demo or hf_token is None:
        return f"(Mode d√©mo actif) R√©sum√© simul√© : {symptomes[:40]}..."

    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }

    # üß† Prompt m√©dical structur√© pour BloomZ
    prompt = f"""
Un patient de sexe inconnu nomm√© {medecin_id} pr√©sente les sympt√¥mes suivants : {symptomes}.
Quels sont le diagnostic, la conduite √† tenir et les examens compl√©mentaires recommand√©s ?
"""

    payload = { "inputs": prompt.strip() }

    try:
        # ‚úÖ Mod√®le gratuit via Inference API
        url = "https://api-inference.huggingface.co/models/bigscience/bloomz-560m"
        response = requests.post(url, headers=headers, json=payload, timeout=60)

        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            else:
                return f"‚ö†Ô∏è Format inattendu : {data}"
        else:
            return f"‚ùå Erreur {response.status_code} : {response.text[:100]}"
    except Exception as e:
        return f"‚ùå Erreur lors de l‚Äôappel IA : {str(e)}"

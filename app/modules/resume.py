import requests

def generer_resume(symptomes: str, medecin_id: str, hf_token: str, mode_demo: bool = False) -> str:
    if mode_demo or hf_token is None:
        return f"(Simulation dÃ©mo) {symptomes[:40]}..."

    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }

    # ğŸ” Construction du prompt pour Mixtral
    prompt = f"""
Vous Ãªtes un mÃ©decin urgentiste.
Voici le cas clinique :
Patient : {medecin_id}
SymptÃ´mes : {symptomes}

Donnez un rÃ©sumÃ© synthÃ©tique mÃ©dical, avec hypothÃ¨se diagnostique et conduite Ã  tenir.
"""

    payload = {
        "inputs": prompt.strip()
    }

    try:
        # âœ… URL corrigÃ©e vers modÃ¨le Mixtral actif
        url = "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
        response = requests.post(url, headers=headers, json=payload, timeout=60)

        if response.status_code == 200:
            data = response.json()

            # ğŸ” Extraction du texte gÃ©nÃ©rÃ©
            if isinstance(data, list) and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            else:
                return f"âš ï¸ Format inattendu reÃ§u : {str(data)}"
        else:
            return f"âŒ Erreur {response.status_code} : {response.text[:120]}"
    except Exception as e:
        return f"âŒ Erreur lors de lâ€™appel IA : {str(e)}"
